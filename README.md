# Speculative Tool Calling

Reduce LLM agent latency by speculatively pre-executing tool calls in parallel with the actor model's reasoning.

## Core Idea

**Traditional Sequential Execution:**
```
Time: 0s                    10s                    12s
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      Actor thinking...     Execute tool
                            â–“â–“
      Total: 12s
```

**Speculative Parallel Execution:**
```
Time: 0s            2s      4s                     10s    10.001s
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
      Actor:        â”‚                              â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    Thinking...

      Spec:   Predict Execute
              â–“â–“      â–“â–“
                      â””â”€â†’ Cache result

                                                   Check cache
                                                   âš¡ Match! Use cached result
                                                   (Tool execution skipped)

      Total: ~10s (2s saved, 17% speedup)
```

**Key insight**: While the actor model (GPT-5) is thinking, a lightweight spec model (GPT-5-mini) predicts and pre-executes the next tool call. If the prediction matches, we use the cached result and skip tool execution entirely.

## Architecture

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚      START          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     node_llm        â”‚
                    â”‚                     â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Actor Model   â”‚  â”‚  Run in parallel
                    â”‚  â”‚ (GPT-5)       â”‚  â”‚  
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚         +           â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Spec Model    â”‚  â”‚
                    â”‚  â”‚ (GPT-5-mini)  â”‚  â”‚
                    â”‚  â”‚ + Pre-execute â”‚  â”‚
                    â”‚  â”‚ + Cache       â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”Œâ”€â”€â”€â”€â†’â”‚    node_tools       â”‚
              â”‚     â”‚                     â”‚
              â”‚     â”‚  Check cache:       â”‚
              â”‚     â”‚  - Match? Use cache â”‚
              â”‚     â”‚  - No? Execute      â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                â”‚
              â”‚                â–¼
              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚     â”‚   should_end?       â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                â”‚
              â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
              â”‚         â”‚             â”‚
              â”‚       Done       Continue
              â”‚         â”‚             â”‚
              â”‚         â–¼             â”‚
              â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”         â”‚
              â”‚     â”‚  END  â”‚         â”‚
              â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
              â”‚                       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Setup

```bash
# Install dependencies
pip install -r requirements.txt

# Set API keys
export OPENAI_API_KEY="your-key"
export SERPER_API_KEY="your-key"  # For web search

# Download GAIA dataset
python3 download_gaia.py
```

## Running Evaluations

### Single Example (Detailed)

```bash
# Run specific example
python3 eval.py gaia_dataset/level1/example_000

# With speculation enabled (default)
python3 eval.py gaia_dataset/level1/example_000

# Baseline (no speculation)
DISABLE_SPECULATION=1 python3 eval.py gaia_dataset/level1/example_000
```

### Batch Evaluation (Multiple Examples)

```bash
# Run all level 1 examples with speculation
python eval.py --batch --level 1

# Run first 10 examples
python eval.py --batch --level 1 --max 10

# Baseline (no speculation)
DISABLE_SPECULATION=1 python eval.py --batch --level 1 --max 10

# Custom output directory
python eval.py --batch --level 1 --output my_results/
```

## Configuration

Set via environment variables:

```bash
# Models
export GAIA_ACTOR_MODEL="gpt-5"           # Main reasoning model
export GAIA_SPEC_MODEL="gpt-5-mini"       # Speculation model

# Limits
export GAIA_MAX_STEPS="15"                # Max reasoning steps

# Speculation
export DISABLE_SPECULATION="1"            # Disable for baseline
```

## Output

**Single mode** shows detailed step-by-step execution:
```
[Step 1] LLM
â±ï¸  LLM call: 8.5s

ğŸ”§ Tool Call:
   Tool: search_with_content
   Args: query = Moon perigee...

[Step 1] TOOLS
â±ï¸  Execution: 0.001s

âœ… USING CACHED RESULT (pre-executed by spec model)
   Saved 1.25s from cache
```

**Batch mode** shows compact progress:
```
[1/10] example_000
âœ… CORRECT (89.2s)

[2/10] example_001
âŒ WRONG (102.3s)

...

FINAL RESULTS
Accuracy:  8/10 (80.0%)
Avg Time:  95.4s
```

## Results

Results are saved to JSON files:

```json
{
  "task_id": "e1fc63a2-...",
  "question": "If Eliud Kipchoge could maintain...",
  "ground_truth": "17",
  "predicted": "17",
  "correct": true,
  "steps": 6,
  "time_seconds": 89.2,
  "spec_hits": 5,
  "spec_misses": 0,
  "spec_predictions": 5
}
```